{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdb5be4",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c6ea91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "# pip install torchvision torchaudio #-> in terminal\n",
    "\n",
    "# Import essentials\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e511e",
   "metadata": {},
   "source": [
    "## 2. Tensor Basics\n",
    "### Creating Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22c41e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "\n",
    "# Special tensors\n",
    "zeros = torch.zeros(3, 4)                    # All zeros\n",
    "ones = torch.ones(2, 3)                      # All ones\n",
    "empty = torch.empty(2, 3)                    # Uninitialized\n",
    "rand = torch.rand(3, 3)                      # Uniform [0, 1)\n",
    "randn = torch.randn(3, 3)                    # Normal dist N(0,1)\n",
    "arange = torch.arange(0, 10, 2)              # [0, 2, 4, 6, 8]\n",
    "linspace = torch.linspace(0, 1, 5)           # 5 points from 0 to 1\n",
    "eye = torch.eye(3)                           # Identity matrix\n",
    "\n",
    "# Like another tensor\n",
    "x_zeros = torch.zeros_like(x)\n",
    "x_ones = torch.ones_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a4325",
   "metadata": {},
   "source": [
    "### Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1dd7e6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "x.shape                 # torch.Size([3, 4, 5])\n",
    "x.size()                # Same as shape\n",
    "x.dtype                 # Data type\n",
    "x.device                # cpu or cuda\n",
    "x.requires_grad         # Gradient tracking\n",
    "x.ndim                  # Number of dimensions (3)\n",
    "x.numel()               # Total elements (60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84d13f",
   "metadata": {},
   "source": [
    "### Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f26a5290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2738,  1.0455,  0.4718,  0.9705],\n",
       "        [-1.2570,  0.3437,  0.9924,  1.4733],\n",
       "        [-1.3379,  0.7186, -1.4230, -1.2065]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x.int()                 # to int32\n",
    "x.long()                # to int64\n",
    "x.float()               # to float32\n",
    "x.double()              # to float64\n",
    "x.half()                # to float16\n",
    "x.bool()                # to boolean\n",
    "\n",
    "# Device conversion\n",
    "# x.to('cuda')            # Move to GPU (2.5 GB+ torch version)\n",
    "x.cpu()                 # Move to CPU\n",
    "x.numpy()               # To NumPy (must be on CPU)\n",
    "arr=np.array(x.numpy())  # From Tensor to NumPy\n",
    "torch.from_numpy(arr)   # From NumPy to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6f400",
   "metadata": {},
   "source": [
    "## 3. Tensor Operations\n",
    "### Basic Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d5182ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Element-wise operations\n",
    "a + b                   # Addition\n",
    "a - b                   # Subtraction\n",
    "a * b                   # Multiplication\n",
    "a / b                   # Division\n",
    "a ** 2                  # Power\n",
    "torch.add(a, b)         # Same as a + b\n",
    "a.add_(b)               # In-place (note the underscore)\n",
    "\n",
    "# Aggregations\n",
    "a.sum()                 # Sum all elements\n",
    "a.float().mean()                # Mean\n",
    "a.float().std()                 # Standard deviation\n",
    "a.max()                 # Maximum value\n",
    "a.min()                 # Minimum value\n",
    "a.argmax()              # Index of max\n",
    "a.argmin()              # Index of min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3514847",
   "metadata": {},
   "source": [
    "### Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f99b0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "\n",
    "# Matrix multiplication\n",
    "C = torch.matmul(A, B)           # (3, 5)\n",
    "C = A @ B                        # Same\n",
    "C = torch.mm(A, B)               # 2D only\n",
    "\n",
    "# Batch matrix multiplication\n",
    "A_batch = torch.randn(10, 3, 4)\n",
    "B_batch = torch.randn(10, 4, 5)\n",
    "C_batch = torch.bmm(A_batch, B_batch)  # (10, 3, 5)\n",
    "\n",
    "# Transpose\n",
    "A.T                              # Transpose\n",
    "A.transpose(0, 1)                # Specify dimensions\n",
    "A.permute(1, 0)                  # General permutation\n",
    "\n",
    "# Other operations\n",
    "A = torch.randn(4, 4)\n",
    "A.inverse()                      # Matrix inverse\n",
    "torch.det(A)                     # Determinant\n",
    "eigenvalues, eigenvectors = torch.linalg.eig(A)  # Eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad10665",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8de74e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4413, -0.5042,  0.5971,  1.0270, -1.1113,  0.0516,  0.8574, -0.1873,\n",
       "         -0.0059,  0.5350, -0.5601, -2.6708]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "\n",
    "# Reshape\n",
    "x.view(6, 4)                     # Must be contiguous\n",
    "x.reshape(6, 4)                  # Works on non-contiguous\n",
    "x.view(-1)                       # Flatten (24,)\n",
    "x.view(2, -1)                    # Auto-calculate (2, 12)\n",
    "\n",
    "# Squeeze & Unsqueeze\n",
    "x = torch.randn(1, 3, 1, 4)\n",
    "x.squeeze()                      # Remove all 1-dims → (3, 4)\n",
    "x.squeeze(0)                     # Remove specific dim → (3, 1, 4)\n",
    "x.unsqueeze(0)                   # Add dim at position 0\n",
    "x.unsqueeze(-1)                  # Add dim at end\n",
    "\n",
    "# Flatten\n",
    "x.flatten()                      # Flatten all\n",
    "x.flatten(start_dim=1)           # Flatten from dim 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30329d",
   "metadata": {},
   "source": [
    "### Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "27737f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 5, 6)\n",
    "\n",
    "# Basic indexing\n",
    "x[0]                             # First element\n",
    "x[:2]                            # First 2 elements\n",
    "x[1:3]                           # Elements 1 and 2\n",
    "x[:, 0]                          # All rows, first column\n",
    "x[..., 0]                        # Last dimension, first element\n",
    "\n",
    "# Boolean indexing\n",
    "mask = x > 0\n",
    "x[mask]                          # All positive values\n",
    "\n",
    "# Fancy indexing\n",
    "indices = torch.tensor([0, 2])\n",
    "x[indices]                       # Select rows 0 and 2\n",
    "\n",
    "# Gathering\n",
    "output = torch.index_select(x, dim=1, index=indices)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a06c82",
   "metadata": {},
   "source": [
    "### Concatenation & Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "009f8431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2197,  0.7318],\n",
       "         [-0.5083, -0.5122]]),\n",
       " tensor([[0.7136],\n",
       "         [0.7368]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2, 3)\n",
    "\n",
    "# Concatenate\n",
    "torch.cat([a, b], dim=0)         # (4, 3)\n",
    "torch.cat([a, b], dim=1)         # (2, 6)\n",
    "\n",
    "# Stack (adds new dimension)\n",
    "torch.stack([a, b], dim=0)       # (2, 2, 3)\n",
    "torch.stack([a, b], dim=1)       # (2, 2, 3)\n",
    "\n",
    "# Split\n",
    "torch.split(a, 1, dim=0)         # Split into chunks\n",
    "torch.chunk(a, 2, dim=1)         # Split into n chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86601be3",
   "metadata": {},
   "source": [
    "## 4. Autograd (Automatic Differentiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "261d784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n",
      "tensor([27.])\n"
     ]
    }
   ],
   "source": [
    "# Enable gradient tracking\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "z = x ** 2 + y ** 3\n",
    "\n",
    "# Backward pass\n",
    "z.backward(retain_graph=True)    # Compute gradients and retain graph to use again\n",
    "\n",
    "# Access gradients\n",
    "print(x.grad)                    # dz/dx = 2x = 4\n",
    "print(y.grad)                    # dz/dy = 3y² = 27\n",
    "\n",
    "# Gradient accumulation\n",
    "z.backward()                     # Gradients accumulate!\n",
    "x.grad.zero_()                   # Zero gradients before next pass\n",
    "\n",
    "# Prevent gradient tracking\n",
    "with torch.no_grad():\n",
    "    z = x ** 2 + y ** 3          # No gradients computed\n",
    "\n",
    "# Detach from computation graph\n",
    "z_detached = z.detach()          # Tensor without gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cd7d9",
   "metadata": {},
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6c81ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "class MyFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x ** 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        return grad_output * 2 * x\n",
    "\n",
    "# Usage\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = MyFunction.apply(x)\n",
    "y.backward()\n",
    "print(x.grad)  # 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39879be",
   "metadata": {},
   "source": [
    "## 5. Neural Network Layers\n",
    "### Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40cdd98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Linear (Fully Connected)\n",
    "linear = nn.Linear(in_features=10, out_features=5, bias=True)\n",
    "\n",
    "# Convolutional\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=64, \n",
    "                   kernel_size=3, stride=1, padding=1)\n",
    "conv1d = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "\n",
    "# Pooling\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "adaptivepool = nn.AdaptiveAvgPool2d((1, 1))  # Output size\n",
    "\n",
    "# Normalization\n",
    "batchnorm = nn.BatchNorm2d(num_features=64)\n",
    "layernorm = nn.LayerNorm(normalized_shape=[10, 20])\n",
    "groupnorm = nn.GroupNorm(num_groups=8, num_channels=64)\n",
    "\n",
    "# Dropout\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "dropout2d = nn.Dropout2d(p=0.5)\n",
    "\n",
    "# Recurrent\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2)\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
    "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2)\n",
    "\n",
    "# Attention\n",
    "attention = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "\n",
    "# Embedding\n",
    "embedding = nn.Embedding(num_embeddings=1000, embedding_dim=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8694b54",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "34eb3d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogSoftmax(dim=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All available as nn.Module or F.function\n",
    "relu = nn.ReLU()\n",
    "# Or: F.relu(x)\n",
    "\n",
    "# Common activations\n",
    "nn.ReLU()\n",
    "nn.LeakyReLU(negative_slope=0.01)\n",
    "nn.PReLU()\n",
    "nn.ELU()\n",
    "nn.GELU()\n",
    "nn.Sigmoid()\n",
    "nn.Tanh()\n",
    "nn.Softmax(dim=1)\n",
    "nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962cad3",
   "metadata": {},
   "source": [
    "## 6. Building Models\n",
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "40f9c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1960aac",
   "metadata": {},
   "source": [
    "### Custom Model (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c61ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate\n",
    "model = MyModel(784, 256, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb35dd",
   "metadata": {},
   "source": [
    "### CNN Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cd660ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8dfdb",
   "metadata": {},
   "source": [
    "### Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f911d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "conv1.weight: torch.Size([32, 1, 3, 3])\n",
      "conv1.bias: torch.Size([32])\n",
      "conv2.weight: torch.Size([64, 32, 3, 3])\n",
      "conv2.bias: torch.Size([64])\n",
      "fc1.weight: torch.Size([128, 3136])\n",
      "fc1.bias: torch.Size([128])\n",
      "fc2.weight: torch.Size([10, 128])\n",
      "fc2.bias: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model architecture\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Access layers\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n",
    "\n",
    "# Freeze/unfreeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze\n",
    "\n",
    "# Apply function to all modules\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83d46e",
   "metadata": {},
   "source": [
    "## 7. Loss Functions & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32a388a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "criterion = nn.CrossEntropyLoss()                    # Multi-class\n",
    "criterion = nn.BCELoss()                             # Binary (needs sigmoid)\n",
    "criterion = nn.BCEWithLogitsLoss()                   # Binary (with logits)\n",
    "criterion = nn.NLLLoss()                             # Negative Log Likelihood\n",
    "\n",
    "# Regression\n",
    "criterion = nn.MSELoss()                             # Mean Squared Error\n",
    "criterion = nn.L1Loss()                              # Mean Absolute Error\n",
    "criterion = nn.SmoothL1Loss()                        # Huber Loss\n",
    "\n",
    "# Other\n",
    "criterion = nn.KLDivLoss()                           # KL Divergence\n",
    "criterion = nn.CosineEmbeddingLoss()                 # Cosine similarity\n",
    "\n",
    "# Usage\n",
    "# outputs = model(inputs)\n",
    "# loss = criterion(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb69915",
   "metadata": {},
   "source": [
    "## 8. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0aa40ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Common optimizers\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "# Optimizer step\n",
    "optimizer.zero_grad()      # Clear gradients\n",
    "# loss.backward()            # Compute gradients\n",
    "optimizer.step()           # Update weights\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                  factor=0.1, patience=10)\n",
    "\n",
    "# Scheduler step\n",
    "# scheduler.step()           # After each epoch\n",
    "# Or for ReduceLROnPlateau:\n",
    "# scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9df97",
   "metadata": {},
   "source": [
    "## 9. Dataset & DataLoader\n",
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "62badfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "# Create dataset\n",
    "# dataset = CustomDataset(data, labels)\n",
    "\n",
    "# Create DataLoader\n",
    "# dataloader = DataLoader(dataset, \n",
    "#                        batch_size=32, \n",
    "#                        shuffle=True, \n",
    "#                        num_workers=4,\n",
    "#                        pin_memory=True)  # Faster GPU transfer\n",
    "\n",
    "# Iterate\n",
    "# for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "    # data, labels = data.to(device), labels.to(device)\n",
    "    # Training code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096d60c",
   "metadata": {},
   "source": [
    "### Built-in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "53a78507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, \n",
    "                               download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, \n",
    "                              download=True, transform=transform)\n",
    "\n",
    "# Other datasets: CIFAR10, CIFAR100, ImageNet, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e51103",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ee6797a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()  # Set to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        # Move to device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Print progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145d932",
   "metadata": {},
   "source": [
    "## 11. Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cd818e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34a71f",
   "metadata": {},
   "source": [
    "## 12. Saving & Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ae35964b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save entire model\n",
    "torch.save(model, 'model.pth')\n",
    "model = torch.load('model.pth', weights_only=False)\n",
    "\n",
    "# Save only weights (recommended)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "model.load_state_dict(torch.load('model_weights.pth', weights_only=False))\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint = {\n",
    "    'epoch': 100,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    'accuracy': 98\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoint.pth', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# Load for inference only\n",
    "model.load_state_dict(torch.load('model_weights.pth', weights_only=False))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefca44",
   "metadata": {},
   "source": [
    "## 13. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f1367820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)  # Assuming 10 classes\n",
    "\n",
    "# Only train final layer\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Or fine-tune entire model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f5246",
   "metadata": {},
   "source": [
    "## 14.  Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "db116cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Common transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, \n",
    "                          saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Test transform (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a07873",
   "metadata": {},
   "source": [
    "## 15. Common Patterns\n",
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Usage\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(...)\n",
    "    val_loss = evaluate(...)\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f4046",
   "metadata": {},
   "source": [
    "### Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "# Ensemble prediction\n",
    "with torch.no_grad():\n",
    "    outputs = [model(inputs) for model in models]\n",
    "    ensemble_output = torch.stack(outputs).mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc4c24",
   "metadata": {},
   "source": [
    "## 16. Tips & Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Use .item() to get Python numbers\n",
    "loss_value = loss.item()  # Not loss (which is a tensor)\n",
    "\n",
    "# Free memory explicitly\n",
    "del large_tensor\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Use appropriate data types\n",
    "x = x.float()  # For most operations\n",
    "x = x.long()   # For indices/labels\n",
    "\n",
    "# Batch operations when possible\n",
    "# Bad:\n",
    "for i in range(len(tensors)):\n",
    "    result.append(model(tensors[i]))\n",
    "\n",
    "# Good:\n",
    "result = model(torch.stack(tensors))\n",
    "\n",
    "# Use in-place operations carefully (they save memory)\n",
    "x.add_(y)    # In-place\n",
    "x = x + y    # Creates new tensor\n",
    "\n",
    "# Move data to GPU once, not in loop\n",
    "inputs = inputs.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(inputs)  # Already on GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
